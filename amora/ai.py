from pydantic import BaseModel

from amora.config import settings
from amora.models import list_models
from amora.providers.bigquery import schema_for_model


def prompt_context(stop="#") -> str:
    """
    Generates a prompt context for project models, which includes the schema of each model as well as documentation
    for each table and column in a data model.

    Examples:
        ```python
        prompt_context()
        ```

    Returns:

        # fixme: DocumentaÃ§Ã£o quebrada. TÃ¡ rolando uma confusÃ£o entre as aspas e tralhas
        ```
        # amora-data-build-tool.amora.steps(id INTEGER,sourceName STRING,unit STRING,value FLOAT,device STRING,creationDate TIMESTAMP,startDate TIMESTAMP,endDate TIMESTAMP)
        # amora-data-build-tool.amora.heart_rate_agg(year INTEGER,month INTEGER)
        # amora-data-build-tool.amora.health(id INTEGER,type STRING,sourceName STRING,sourceVersion STRING,unit STRING,value FLOAT,device STRING,creationDate TIMESTAMP,startDate TIMESTAMP,endDate TIMESTAMP)
        # amora-data-build-tool.amora.step_count_by_source(value_avg FLOAT,value_sum FLOAT,value_count INTEGER,source_name STRING,event_timestamp TIMESTAMP)
        # amora-data-build-tool.amora.heart_rate_over100(unit STRING,value FLOAT,creationDate TIMESTAMP,id INTEGER)
        # amora-data-build-tool.amora.heart_rate(id INTEGER,sourceName STRING,unit STRING,value FLOAT,device STRING,creationDate TIMESTAMP,startDate TIMESTAMP,endDate TIMESTAMP)
        # amora-data-build-tool.amora.array_repeated_fields(str_arr STRING,int_arr INTEGER,id STRING)
        # Column creationDate: Data de inserÃ§Ã£o dos dados
        # Column device: Dispositivo de origem dos dados
        # Column endDate: Data do fim da medida
        # Column event_timestamp: Moment if time of which those features where observed
        # Column id: Identificador Ãºnico da medida
        # Column sourceName: Origem dos dados
        # Column sourceVersion: VersÃ£o da origem de dados
        # Column source_name: Source of the metric
        # Column startDate: Data do inÃ­cio da medida
        # Column type: Tipo da mÃ©trica coletada
        # Column unit: Unidade de medida
        # Column value: Valor observado
        # Column value_avg: Average step count of the hour
        # Column value_count: Count of step count samples of the hour
        # Column value_sum: Sum of the step counts of the hour
        # Table amora-data-build-tool.amora.array_repeated_fields: Example model with array columns
        # Table amora-data-build-tool.amora.health: Health data exported by the Apple Health App
        # Table amora-data-build-tool.amora.heart_rate: Undocumented! Generated by Amora Data Build Tool ðŸ’š
        # Table amora-data-build-tool.amora.heart_rate_agg: Undocumented! Generated by Amora Data Build Tool ðŸ’š
        # Table amora-data-build-tool.amora.heart_rate_over100: Undocumented! Generated by Amora Data Build Tool ðŸ’š
        # Table amora-data-build-tool.amora.step_count_by_source: Undocumented! Generated by Amora Data Build Tool ðŸ’š
        # Table amora-data-build-tool.amora.steps: Health automatically counts your steps, walking, and running distances. This table stores step measurement events
        ```
    """
    if len(stop) > 4:
        raise ValueError("Up to 4 sequences where the API will stop generating further tokens")

    def schema():
        for model, path in list_models():
            schema = schema_for_model(model)
            columns = ",".join(f"{field.name} {field.field_type}" for field in schema)
            yield f"{stop} {model.unique_name()}({columns})"

    def columns_documentation():
        for (model, _model_path) in list_models():
            yield f"{stop} Table {model.unique_name()}: {model.__model_config__.description}"
            for column in model.__table__.columns:
                if column.doc is not None:
                    yield f"{stop} Column {column.key}: {column.doc}"

    schema_context = "\n".join(schema())
    columns_documentation_context = "\n".join(sorted(set(columns_documentation())))

    return f"{schema_context}\n{columns_documentation_context}"


class SQLPromptAnswer(BaseModel):
    sql: str

    completion_tokens: int
    prompt_tokens: int
    total_tokens: int

    request_params: dict
    response_ms: int

    class Config:
        arbitrary_types_allowed = True

    @property
    def estimated_cost(self):
        """
        OpenAI has a per 1000 tokens pricing. You can think of tokens as pieces of words, where 1,000 tokens is
        about 750 words.

        Read More:
            https://openai.com/pricing

        Returns:
            The estimated cost of completion
        """
        return (self.total_tokens / 1000) * settings.OPENAI_COST_PER_1000_TOKENS
