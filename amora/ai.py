import json
from pathlib import Path
from typing import List

from pydantic import BaseModel

from amora.models import list_models
from amora.providers.bigquery import schema_for_model


class PromptContext(BaseModel):
    model_schema: List[str]
    columns_documentation: List[str]

    @classmethod
    def from_project(cls, stop="#") -> "PromptContext":
        """
        Generates a prompt context for project models, which includes the schema of each model as well as documentation
        for each table and column in a data model.

        Examples:

            ```python
            PromptContext.from_project()
            ```

            ```
            # amora-data-build-tool.amora.steps(id INTEGER,sourceName STRING,unit STRING,value FLOAT,device STRING,creationDate TIMESTAMP,startDate TIMESTAMP,endDate TIMESTAMP)
            # amora-data-build-tool.amora.heart_rate_agg(year INTEGER,month INTEGER)
            # amora-data-build-tool.amora.health(id INTEGER,type STRING,sourceName STRING,sourceVersion STRING,unit STRING,value FLOAT,device STRING,creationDate TIMESTAMP,startDate TIMESTAMP,endDate TIMESTAMP)
            # amora-data-build-tool.amora.step_count_by_source(value_avg FLOAT,value_sum FLOAT,value_count INTEGER,source_name STRING,event_timestamp TIMESTAMP)
            # amora-data-build-tool.amora.heart_rate_over100(unit STRING,value FLOAT,creationDate TIMESTAMP,id INTEGER)
            # amora-data-build-tool.amora.heart_rate(id INTEGER,sourceName STRING,unit STRING,value FLOAT,device STRING,creationDate TIMESTAMP,startDate TIMESTAMP,endDate TIMESTAMP)
            # amora-data-build-tool.amora.array_repeated_fields(str_arr STRING,int_arr INTEGER,id STRING)
            # Column creationDate: Data de inserÃ§Ã£o dos dados
            # Column device: Dispositivo de origem dos dados
            # Column endDate: Data do fim da medida
            # Column event_timestamp: Moment if time of which those features where observed
            # Column id: Identificador Ãºnico da medida
            # Column sourceName: Origem dos dados
            # Column sourceVersion: VersÃ£o da origem de dados
            # Column source_name: Source of the metric
            # Column startDate: Data do inÃ­cio da medida
            # Column type: Tipo da mÃ©trica coletada
            # Column unit: Unidade de medida
            # Column value: Valor observado
            # Column value_avg: Average step count of the hour
            # Column value_count: Count of step count samples of the hour
            # Column value_sum: Sum of the step counts of the hour
            # Table amora-data-build-tool.amora.array_repeated_fields: Example model with array columns
            # Table amora-data-build-tool.amora.health: Health data exported by the Apple Health App
            # Table amora-data-build-tool.amora.heart_rate: Undocumented! Generated by Amora Data Build Tool ðŸ’š
            # Table amora-data-build-tool.amora.heart_rate_agg: Undocumented! Generated by Amora Data Build Tool ðŸ’š
            # Table amora-data-build-tool.amora.heart_rate_over100: Undocumented! Generated by Amora Data Build Tool ðŸ’š
            # Table amora-data-build-tool.amora.step_count_by_source: Undocumented! Generated by Amora Data Build Tool ðŸ’š
            # Table amora-data-build-tool.amora.steps: Health automatically counts your steps, walking, and running distances. This table stores step measurement events
            ```

        Returns:
            The prompt context to be used for completion

        """

        def schema():
            for model, path in list_models():
                schema = schema_for_model(model)
                columns = ",".join(
                    f"{field.name} {field.field_type}" for field in schema
                )
                yield f"{stop} {model.unique_name()}({columns})"

        def columns_documentation():
            for (model, _model_path) in list_models():
                yield f"{stop} Table {model.unique_name()}: {model.__model_config__.description}"
                for column in model.__table__.columns:
                    if column.doc is not None:
                        yield f"{stop} Column {column.key}: {column.doc}"

        return cls(model_schema=schema(), columns_documentation=columns_documentation())

    @classmethod
    def from_dbt_manifest(cls, manifest_path: Path, stop="#") -> "PromptContext":
        """
        Generates a prompt context for models defined in a DBT project manifest. It takes in a `manifest_path` argument
        which is the path to the [manifest](https://docs.getdbt.com/reference/artifacts/manifest-json) file in the DBT project.


        Args:
            manifest_path:  the path to the manifest file in the DBT project.
            stop: Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence. More on: https://platform.openai.com/docs/api-reference/completions/create#completions/create-stop

        Returns:
            The prompt context to be used for completion

        """
        with open(manifest_path) as fp:
            manifest = json.load(fp)

        models = tuple(
            filter(
                lambda node: node["resource_type"] == "model"
                and node["config"]["materialized"] in ("table", "view")
                and node["docs"]["show"],
                manifest["nodes"].values(),
            )
        )

        def unique_name(model):
            return f"{model['database']}.{model['schema']}.{model['name']}"

        def schema():
            for model in models:
                columns = ",".join(
                    f"{column_data['name']} {column_data['data_type']}"
                    if column_data["data_type"]
                    else column_data["name"]
                    for column_data in model["columns"].values()
                )
                yield f"{stop} {unique_name(model)}({columns})"

        def columns_documentation():
            for model in models:
                table_description = model["description"].replace("\n", " ")
                yield f"{stop} Table {unique_name(model)}: {table_description}"
                for column_data in model["columns"].values():
                    yield f"{stop} Column {column_data['name']}: {column_data['description']}"

        return cls(model_schema=schema(), columns_documentation=columns_documentation())

    def __str__(self):
        schema_context = "\n".join(self.model_schema)
        columns_documentation_context = "\n".join(
            sorted(set(self.columns_documentation))
        )

        return f"{schema_context}\n{columns_documentation_context}"
